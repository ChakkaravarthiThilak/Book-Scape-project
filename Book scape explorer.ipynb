{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efbd17b-cbba-4402-aa9f-9578b5224ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter search keys (comma-separated, e.g., fiction,science,history):  fiction,science,history,education\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing search key: fiction\n",
      "Total books available for 'fiction': 7228\n",
      "Fetching books 1 to 40 for 'fiction'...\n",
      "Fetching books 41 to 80 for 'fiction'...\n",
      "Fetching books 81 to 120 for 'fiction'...\n",
      "Fetching books 121 to 160 for 'fiction'...\n",
      "Fetching books 161 to 200 for 'fiction'...\n",
      "Fetching books 201 to 240 for 'fiction'...\n",
      "Fetching books 241 to 280 for 'fiction'...\n",
      "Fetching books 281 to 320 for 'fiction'...\n",
      "Fetching books 321 to 360 for 'fiction'...\n",
      "Fetching books 361 to 400 for 'fiction'...\n",
      "Fetching books 401 to 440 for 'fiction'...\n",
      "Fetching books 441 to 480 for 'fiction'...\n",
      "Fetching books 481 to 520 for 'fiction'...\n",
      "Fetching books 521 to 560 for 'fiction'...\n",
      "Fetching books 561 to 600 for 'fiction'...\n",
      "Fetching books 601 to 640 for 'fiction'...\n",
      "Fetching books 641 to 680 for 'fiction'...\n",
      "Fetching books 681 to 720 for 'fiction'...\n",
      "Fetching books 721 to 760 for 'fiction'...\n",
      "Fetching books 761 to 800 for 'fiction'...\n",
      "Fetching books 801 to 840 for 'fiction'...\n",
      "Fetching books 841 to 880 for 'fiction'...\n",
      "Fetching books 881 to 920 for 'fiction'...\n",
      "Fetching books 921 to 960 for 'fiction'...\n",
      "Fetching books 961 to 1000 for 'fiction'...\n",
      "Total books collected for 'fiction': 1000\n",
      "Processing search key: science\n",
      "Total books available for 'science': 4099\n",
      "Fetching books 1 to 40 for 'science'...\n",
      "Fetching books 41 to 80 for 'science'...\n",
      "Fetching books 81 to 120 for 'science'...\n",
      "Fetching books 121 to 160 for 'science'...\n",
      "Fetching books 161 to 200 for 'science'...\n",
      "Fetching books 201 to 240 for 'science'...\n",
      "Fetching books 241 to 280 for 'science'...\n",
      "Fetching books 281 to 320 for 'science'...\n",
      "Fetching books 321 to 360 for 'science'...\n",
      "Fetching books 361 to 400 for 'science'...\n",
      "Fetching books 401 to 440 for 'science'...\n",
      "Fetching books 441 to 480 for 'science'...\n",
      "Fetching books 481 to 520 for 'science'...\n",
      "Fetching books 521 to 560 for 'science'...\n",
      "Fetching books 561 to 600 for 'science'...\n",
      "Fetching books 601 to 640 for 'science'...\n",
      "Fetching books 641 to 680 for 'science'...\n",
      "Fetching books 681 to 720 for 'science'...\n",
      "Fetching books 721 to 760 for 'science'...\n",
      "Fetching books 761 to 800 for 'science'...\n",
      "Fetching books 801 to 840 for 'science'...\n",
      "Fetching books 841 to 880 for 'science'...\n",
      "Fetching books 881 to 920 for 'science'...\n",
      "Fetching books 921 to 960 for 'science'...\n",
      "Fetching books 961 to 1000 for 'science'...\n",
      "Total books collected for 'science': 1000\n",
      "Processing search key: history\n",
      "Total books available for 'history': 5736\n",
      "Fetching books 1 to 40 for 'history'...\n",
      "Fetching books 41 to 80 for 'history'...\n",
      "Fetching books 81 to 120 for 'history'...\n",
      "Fetching books 121 to 160 for 'history'...\n",
      "Fetching books 161 to 200 for 'history'...\n",
      "Fetching books 201 to 240 for 'history'...\n",
      "Fetching books 241 to 280 for 'history'...\n",
      "Fetching books 281 to 320 for 'history'...\n",
      "Fetching books 321 to 360 for 'history'...\n",
      "Fetching books 361 to 400 for 'history'...\n",
      "Fetching books 401 to 440 for 'history'...\n",
      "Fetching books 441 to 480 for 'history'...\n",
      "Fetching books 481 to 520 for 'history'...\n",
      "Fetching books 521 to 560 for 'history'...\n",
      "Fetching books 561 to 600 for 'history'...\n",
      "Fetching books 601 to 640 for 'history'...\n",
      "Fetching books 641 to 680 for 'history'...\n",
      "Fetching books 681 to 720 for 'history'...\n",
      "Fetching books 721 to 760 for 'history'...\n",
      "Fetching books 761 to 800 for 'history'...\n",
      "Fetching books 801 to 840 for 'history'...\n",
      "Fetching books 841 to 880 for 'history'...\n",
      "Fetching books 881 to 920 for 'history'...\n",
      "Fetching books 921 to 960 for 'history'...\n",
      "Fetching books 961 to 1000 for 'history'...\n",
      "Total books collected for 'history': 1000\n",
      "Processing search key: education\n",
      "Total books available for 'education': 3589\n",
      "Fetching books 1 to 40 for 'education'...\n",
      "Fetching books 41 to 80 for 'education'...\n",
      "Fetching books 81 to 120 for 'education'...\n",
      "Fetching books 121 to 160 for 'education'...\n",
      "Fetching books 161 to 200 for 'education'...\n",
      "Fetching books 201 to 240 for 'education'...\n",
      "Fetching books 241 to 280 for 'education'...\n",
      "Fetching books 281 to 320 for 'education'...\n",
      "Fetching books 321 to 360 for 'education'...\n",
      "Fetching books 361 to 400 for 'education'...\n",
      "Fetching books 401 to 440 for 'education'...\n",
      "Fetching books 441 to 480 for 'education'...\n",
      "Fetching books 481 to 520 for 'education'...\n",
      "Fetching books 521 to 560 for 'education'...\n",
      "Fetching books 561 to 600 for 'education'...\n",
      "Fetching books 601 to 640 for 'education'...\n",
      "Fetching books 641 to 680 for 'education'...\n",
      "Fetching books 681 to 720 for 'education'...\n",
      "Fetching books 721 to 760 for 'education'...\n",
      "Fetching books 761 to 800 for 'education'...\n",
      "Fetching books 801 to 840 for 'education'...\n",
      "Fetching books 841 to 880 for 'education'...\n",
      "Fetching books 881 to 920 for 'education'...\n",
      "Fetching books 921 to 960 for 'education'...\n",
      "Fetching books 961 to 1000 for 'education'...\n",
      "Total books collected for 'education': 1000\n",
      "Raw data saved to 'raw_books_data.json'.\n",
      "Cleaned data saved to 'cleaned_books_data.json'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELCOT\\AppData\\Local\\Temp\\ipykernel_5196\\459254275.py:152: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  books_df['year'].fillna(mean_year, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# API endpoint and key\n",
    "API_URL = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "API_KEY = \"AIzaSyAWUUhpWNyLtC-32_EftMmj0yqjtuQ2Nq0\"  # API key\n",
    "BATCH_SIZE = 40  # Maximum books per request\n",
    "MAX_BOOKS = 1000  # Total books to fetch\n",
    "\n",
    "# Fetch books function\n",
    "def fetch_books(search_key, start_index=0):\n",
    "    \"\"\"Fetches a batch of books from the Google Books API for a specific search key.\"\"\"\n",
    "    params = {\n",
    "        'q': search_key,  # Dynamic search query\n",
    "        'startIndex': start_index,\n",
    "        'maxResults': BATCH_SIZE,\n",
    "        'key': API_KEY,\n",
    "    }\n",
    "    response = requests.get(API_URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.json().get('error', {}).get('message', 'Unknown error')}\")\n",
    "        return None\n",
    "\n",
    "# Collect books function\n",
    "def collect_books(total_books, search_key):\n",
    "    \"\"\"Collects books data for a given search key, ensuring no requests go beyond total available results.\"\"\"\n",
    "    start_index = 0\n",
    "    collected_books = 0\n",
    "    book_data = []\n",
    "\n",
    "    # Get total available books\n",
    "    initial_response = fetch_books(search_key, start_index)\n",
    "    if initial_response and \"totalItems\" in initial_response:\n",
    "        total_available = initial_response[\"totalItems\"]\n",
    "        print(f\"Total books available for '{search_key}': {total_available}\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve total available books.\")\n",
    "        return book_data\n",
    "\n",
    "    # Adjust total_books to the available number\n",
    "    total_books = min(total_books, total_available)\n",
    "\n",
    "    while collected_books < total_books:\n",
    "        print(f\"Fetching books {collected_books + 1} to {min(collected_books + BATCH_SIZE, total_books)} for '{search_key}'...\")\n",
    "        data = fetch_books(search_key, start_index)\n",
    "        if data and \"items\" in data:\n",
    "            book_data.extend(data[\"items\"])\n",
    "            collected_books += len(data[\"items\"])\n",
    "            if collected_books >= total_books:\n",
    "                break\n",
    "        else:\n",
    "            print(\"No more items available or an error occurred.\")\n",
    "            break\n",
    "\n",
    "        # Update the start index and avoid rate limits\n",
    "        start_index += BATCH_SIZE\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(f\"Total books collected for '{search_key}': {collected_books}\")\n",
    "    return book_data\n",
    "\n",
    "# Process books data\n",
    "def process_books_data(raw_books, search_key):\n",
    "    \"\"\"Processes raw books data into a structured DataFrame with real prices.\"\"\"\n",
    "    processed_books = []\n",
    "    for book in raw_books:\n",
    "        volume_info = book.get(\"volumeInfo\", {})\n",
    "        sale_info = book.get(\"saleInfo\", {})\n",
    "        industry_identifiers = volume_info.get(\"industryIdentifiers\", [])\n",
    "        \n",
    "        # Only include books with a valid saleability status and price data\n",
    "        if sale_info.get(\"saleability\", \"NOT_FOR_SALE\") == \"FOR_SALE\":\n",
    "            processed_books.append({\n",
    "                \"book_id\": book.get(\"id\", \"\"),\n",
    "                \"search_key\": search_key,\n",
    "                \"book_title\": volume_info.get(\"title\", \"No Title Available\"),\n",
    "                \"book_subtitle\": volume_info.get(\"subtitle\", \"\"),\n",
    "                \"book_authors\": \", \".join(volume_info.get(\"authors\", [\"Unknown\"])),\n",
    "                \"book_description\": volume_info.get(\"description\", \"No Description Available\"),\n",
    "                \"industryIdentifiers\": \", \".join([identifier.get(\"identifier\", \"\") for identifier in industry_identifiers]),\n",
    "                \"text_readingModes\": volume_info.get(\"readingModes\", {}).get(\"text\", False),\n",
    "                \"image_readingModes\": volume_info.get(\"readingModes\", {}).get(\"image\", False),\n",
    "                \"pageCount\": volume_info.get(\"pageCount\", 0),\n",
    "                \"categories\": \", \".join(volume_info.get(\"categories\", [])),\n",
    "                \"language\": volume_info.get(\"language\", \"Unknown\"),\n",
    "                \"imageLinks\": volume_info.get(\"imageLinks\", {}).get(\"thumbnail\", \"\"),\n",
    "                \"ratingsCount\": volume_info.get(\"ratingsCount\", 0),\n",
    "                \"averageRating\": volume_info.get(\"averageRating\", 0.0),\n",
    "                \"country\": sale_info.get(\"country\", \"Unknown\"),\n",
    "                \"saleability\": sale_info.get(\"saleability\", \"Unknown\"),\n",
    "                \"isEbook\": sale_info.get(\"isEbook\", False),\n",
    "                \"amount_listPrice\": sale_info.get(\"listPrice\", {}).get(\"amount\", None),\n",
    "                \"currencyCode_listPrice\": sale_info.get(\"listPrice\", {}).get(\"currencyCode\", \"\"),\n",
    "                \"amount_retailPrice\": sale_info.get(\"retailPrice\", {}).get(\"amount\", None),\n",
    "                \"currencyCode_retailPrice\": sale_info.get(\"retailPrice\", {}).get(\"currencyCode\", \"\"),\n",
    "                \"buyLink\": sale_info.get(\"buyLink\", \"\"),\n",
    "                \"year\": volume_info.get(\"publishedDate\", \"Unknown\"),\n",
    "                \"publisher\": volume_info.get(\"publisher\", \"Unknown\"),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(processed_books)\n",
    "\n",
    "# Main execution\n",
    "search_keys = input(\"Enter search keys (comma-separated, e.g., fiction,science,history): \").split(',')\n",
    "all_books_data = []\n",
    "\n",
    "# Collect books for each search key\n",
    "for search_key in search_keys:\n",
    "    search_key = search_key.strip()\n",
    "    print(f\"Processing search key: {search_key}\")\n",
    "    books_data = collect_books(MAX_BOOKS, search_key)\n",
    "    all_books_data.extend(books_data)\n",
    "\n",
    "# Save raw data\n",
    "with open('raw_books_data.json', 'w') as f:\n",
    "    json.dump(all_books_data, f, indent=4)\n",
    "print(\"Raw data saved to 'raw_books_data.json'.\")\n",
    "\n",
    "# Process and clean the data\n",
    "processed_books = []\n",
    "for search_key in search_keys:\n",
    "    filtered_books = [book for book in all_books_data if search_key in book.get(\"searchInfo\", {}).get(\"textSnippet\", \"\")]\n",
    "    processed_books.extend(process_books_data(filtered_books, search_key).to_dict(orient='records'))\n",
    "\n",
    "# Create a final DataFrame\n",
    "books_df = pd.DataFrame(processed_books)\n",
    "\n",
    "# Handle missing values\n",
    "default_values = {\n",
    "    \"book_title\": \"No Title Available\",\n",
    "    \"book_authors\": \"Unknown\",\n",
    "    \"book_description\": \"No Description Available\",\n",
    "    \"categories\": \"Uncategorized\",\n",
    "    \"language\": \"Unknown\",\n",
    "    \"country\": \"Unknown\",\n",
    "    \"publisher\": \"Unknown\",\n",
    "}\n",
    "\n",
    "for column, default_value in default_values.items():\n",
    "    if column in books_df.columns:\n",
    "        books_df[column] = books_df[column].fillna(default_value)\n",
    "\n",
    "# Handle the 'year' column with a flexible approach\n",
    "books_df['year'] = pd.to_numeric(books_df['year'], errors='coerce')  # Convert 'Unknown' to NaN\n",
    "\n",
    "# Strategy: Replace NaN years with the mean year\n",
    "mean_year = books_df['year'].mean()\n",
    "books_df['year'].fillna(mean_year, inplace=True)\n",
    "\n",
    "# Save cleaned data\n",
    "books_df.to_json(\"cleaned_books_data.json\", orient=\"records\", indent=4)\n",
    "print(\"Cleaned data saved to 'cleaned_books_data.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93035e81-2272-4ff1-9fba-a7365cc9f359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_id                     0\n",
      "search_key                  0\n",
      "book_title                  0\n",
      "book_subtitle               0\n",
      "book_authors                0\n",
      "book_description            0\n",
      "industryIdentifiers         0\n",
      "text_readingModes           0\n",
      "image_readingModes          0\n",
      "pageCount                   0\n",
      "categories                  0\n",
      "language                    0\n",
      "imageLinks                  0\n",
      "ratingsCount                0\n",
      "averageRating               0\n",
      "country                     0\n",
      "saleability                 0\n",
      "isEbook                     0\n",
      "amount_listPrice            0\n",
      "currencyCode_listPrice      0\n",
      "amount_retailPrice          0\n",
      "currencyCode_retailPrice    0\n",
      "buyLink                     0\n",
      "year                        0\n",
      "publisher                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in each column\n",
    "null_counts = books_df.isnull().sum()\n",
    "\n",
    "# Display the count of null values\n",
    "print(null_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83cd5f2b-1b6b-4b97-a736-6f00949f8f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check for columns with null values\n",
    "null_columns = null_counts[null_counts > 0]\n",
    "print(null_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56d661c5-09bf-4ee1-a3e3-345fa2b4c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in d:\\c22\\ct\\lib\\site-packages (9.1.0)\n",
      "Requirement already satisfied: sqlalchemy in d:\\c22\\ct\\lib\\site-packages (2.0.34)\n",
      "Requirement already satisfied: pandas in d:\\c22\\ct\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in d:\\c22\\ct\\lib\\site-packages (from sqlalchemy) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\c22\\ct\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\c22\\ct\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\c22\\ct\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\c22\\ct\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\c22\\ct\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\c22\\ct\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python sqlalchemy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88553342-15f8-4f54-aad3-b4ab651584cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully imported to MySQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Set up your MySQL connection details\n",
    "username = 'root'  # MySQL username\n",
    "password = 'thilak'  # MySQL password\n",
    "host = 'localhost'  # MySQL host (default is 'localhost')\n",
    "database = 'books_db'  # The database name\n",
    "\n",
    "# Create the connection using SQLAlchemy\n",
    "engine = create_engine(f'mysql+mysqlconnector://{username}:{password}@{host}/{database}')\n",
    "\n",
    "# Write the DataFrame to the MySQL table\n",
    "books_df.to_sql('books', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data successfully imported to MySQL!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3153e018-2db8-4582-9ec7-e378bc1d2592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_load_data(filepath=\"raw_books_data.json\"):\n",
    "    # ... (rest of your cleaning code)\n",
    "\n",
    "    # Handle missing \"year\" values\n",
    "    df['year'] = pd.to_numeric(df['year'], errors='coerce')  # Try converting to numeric\n",
    "    df['year'].fillna(2023, inplace=True)  # Fill missing values with a default year  \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf82eb8-63cb-4990-ae4f-edcc430a9395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
